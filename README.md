# AR Guidance for Partially Visually Impaired Drivers

Welcome to **AR Guidance for Partially Visually Impaired Drivers**, a pioneering final-year project designed to empower drivers with partial visual impairments through innovative augmented reality (AR) technology. This application assists individuals with **peripheral vision issues**, **distance vision problems**, and **color blindness**, enabling safer and more confident driving experiences with real-time visual and voice-based guidance.

## Project Overview

Driving with partial visual impairments can be challenging and risky. This project leverages cutting-edge AR technology to provide real-time assistance, acting as a **Heads-Up Display (HUD)** for drivers, complemented by **voice alerts** to minimize the need to glance at the phone. By offering tailored support based on the user's specific impairment, the app enhances road safety and accessibility.

### Key Features
- **User Onboarding**: Users create an account and answer three simple questions regarding their visual impairments (peripheral vision, distance vision, or color blindness).
- **Dual Modes**:
  - **Simple Mode**: A minimalist interface delivering basic guidance and voice alerts.
  - **AR Mode**: An immersive HUD experience with real-time AR overlays and synchronized voice notifications for navigation and hazard detection.
- **Voice Alerts**: Real-time audio cues ensure drivers stay informed without diverting their attention from the road.
- **Personalized Assistance**: Guidance adapts to the user’s specific visual impairment for a seamless driving experience.
- **Frontend Built with React Native**: A responsive and user-friendly mobile interface.

## How It Works
1. **Account Creation**: Sign up to get started.
2. **Impairment Assessment**: Answer three quick questions about your vision (peripheral, distance, or color perception).
3. **Home Screen**: Choose between Simple Mode or AR Mode based on your preference.
4. **Real-Time Guidance**: Drive with confidence as the app provides live AR visuals and voice alerts tailored to your needs, keeping your focus on the road.

## Tech Stack
- **Frontend**: React Native  
  - A cross-platform mobile app delivering a smooth and intuitive user experience with integrated voice alert functionality.
- **Backend**: [Backend Repository](https://github.com/Mudasir12315/AR-Guidance-For-Visually-Impaired-Drivers-Backend.git)  
  - Handles user data, authentication, and real-time processing (see the backend repo for more details).

## Installation & Setup
To run the frontend locally:
1. Clone this repository:
   ```bash
   git clone https://github.com/Mudasir12315/MAP_Project.git
   ```
2. Navigate to the project directory:
   ```bash
   cd your-repo-name
   ```
3. Install dependencies:
   ```bash
   npm install
   ```
4. Start the app:
   ```bash
   npx react-native run-android
   ```
   *(Ensure you have a compatible emulator or device connected.)*

## Backend Repository
For the server-side logic, authentication, and real-time data processing, check out the backend code here:  
[**Backend Repository Link**](https://github.com/Mudasir12315/YOLO_FYP.git)

## Future Enhancements
- Integration with vehicle sensors for enhanced accuracy.
- Voice command support for hands-free operation and interaction.
- Multi-language support for voice alerts to broaden accessibility.

## Why This Project Matters
This project bridges the gap between technology and accessibility, offering a practical solution for partially visually impaired drivers. By combining AR with personalized guidance and voice alerts, it promotes independence and safety on the road, reducing reliance on visual input alone.

## License
This project is licensed under the [MIT License](LICENSE) – feel free to use, modify, and distribute it as needed.